{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b19c5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d9a890ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\hp\\Downloads\\a1_RestaurantReviews_HistoricDump.tsv\", sep = '\\t', quoting  = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "af5ebeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e41ad80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 2)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "403775c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    496\n",
       "0    404\n",
       "Name: Liked, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Liked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "68dc9823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "68a54207",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list.remove('no')\n",
    "stopwords_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "64eeade4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Honeslty it didn't taste THAT fresh.)\""
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a525f",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7fe885ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "17458b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to remove html tags\n",
    "from bs4 import BeautifulSoup\n",
    "def remove_html_tags(text):\n",
    "    return BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "##Case-Standardization\n",
    "def to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "##Standardizing Accent Characters\n",
    "import unicodedata\n",
    "def standardize_accented_chars(text):\n",
    " return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "##Dealing with URLs\n",
    "def remove_url(text):\n",
    " return re.sub(r'https?:\\S*', '', text)\n",
    "\n",
    "##Expanding Contractions\n",
    "import contractions\n",
    "def expand_contractions(text):\n",
    "    expanded_words = [] \n",
    "    for word in text.split():\n",
    "       expanded_words.append(contractions.fix(word)) \n",
    "    return ' '.join(expanded_words)\n",
    "\n",
    "##Removing Mentions and Hashtags\n",
    "def remove_mentions_and_tags(text):\n",
    "    text = re.sub(r'@\\S*', '', text)\n",
    "    return re.sub(r'#\\S*', '', text)\n",
    "                  \n",
    "##Removing Special Characters\n",
    "def remove_special_characters(text):\n",
    "    # define the pattern to keep\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pat, '', text)\n",
    "\n",
    "##Removing Digits\n",
    "def remove_numbers(text):\n",
    "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pattern, '', text)\n",
    "                  \n",
    "##Removing Puncuations                 \n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([c for c in text if c not in string.punctuation])\n",
    "                  \n",
    "def get_stem(text):\n",
    "    stemmer = nltk.porter.PorterStemmer()\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "def get_lemma(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fca53fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Using Porter Stemming\n",
    "cleaned_reviews1 = []\n",
    "cleaned_reviews2 = []\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for review in df['Review']:\n",
    "    review = remove_html_tags(review)\n",
    "    review = to_lowercase(review)\n",
    "    review = standardize_accented_chars(review)\n",
    "    review = remove_url(review)\n",
    "    review = expand_contractions(review)\n",
    "    review = remove_mentions_and_tags(review)\n",
    "    review = remove_special_characters(review)\n",
    "    review = remove_numbers(review)\n",
    "    review = remove_punctuation(review)\n",
    "    review = get_stem(review)\n",
    "    \n",
    "    cleaned_reviews1.append(review)\n",
    "    \n",
    "df.insert(1, \"cleaned_reviews1\", cleaned_reviews1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b74d4e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Using Lemmetizer\n",
    "for review in df['Review']:\n",
    "    review = remove_html_tags(review)\n",
    "    review = to_lowercase(review)\n",
    "    review = standardize_accented_chars(review)\n",
    "    review = remove_url(review)\n",
    "    review = expand_contractions(review)\n",
    "    review = remove_mentions_and_tags(review)\n",
    "    review = remove_special_characters(review)\n",
    "    review = remove_numbers(review)\n",
    "    review = remove_punctuation(review)\n",
    "    review = get_lemma(review)\n",
    "    \n",
    "    cleaned_reviews2.append(review)\n",
    "df.insert(1, \"cleaned_reviews2\", cleaned_reviews2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6dab34af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>cleaned_reviews2</th>\n",
       "      <th>cleaned_reviews1</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>wow loved this place</td>\n",
       "      <td>wow love thi place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>crust is not good</td>\n",
       "      <td>crust is not good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>not tasty and the texture wa just nasty</td>\n",
       "      <td>not tasti and the textur wa just nasti</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "      <td>stop by dure the late may bank holiday off ric...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>the selection on the menu wa great and so were...</td>\n",
       "      <td>the select on the menu wa great and so were th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0                           Wow... Loved this place.   \n",
       "1                                 Crust is not good.   \n",
       "2          Not tasty and the texture was just nasty.   \n",
       "3  Stopped by during the late May bank holiday of...   \n",
       "4  The selection on the menu was great and so wer...   \n",
       "\n",
       "                                    cleaned_reviews2  \\\n",
       "0                               wow loved this place   \n",
       "1                                  crust is not good   \n",
       "2            not tasty and the texture wa just nasty   \n",
       "3  stopped by during the late may bank holiday of...   \n",
       "4  the selection on the menu wa great and so were...   \n",
       "\n",
       "                                    cleaned_reviews1  Liked  \n",
       "0                                 wow love thi place      1  \n",
       "1                                  crust is not good      0  \n",
       "2             not tasti and the textur wa just nasti      0  \n",
       "3  stop by dure the late may bank holiday off ric...      1  \n",
       "4  the select on the menu wa great and so were th...      1  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3b1a2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5c93462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = cv.fit_transform(df['cleaned_reviews1']).toarray()\n",
    "X2 = cv.fit_transform(df['cleaned_reviews2']).toarray()\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3d91703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 Shape: (900, 1420)\n",
      "X2 Shape: (900, 1420)\n",
      "y Shape: (900,)\n"
     ]
    }
   ],
   "source": [
    "print('X1 Shape:', X1.shape)\n",
    "print('X2 Shape:', X2.shape)\n",
    "print('y Shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "719b8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving BoW dictionary to later use in prediction\n",
    "import pickle\n",
    "bow_path = 'c1_BoW_Sentiment_Model.pkl'\n",
    "pickle.dump(cv, open(bow_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "19efd3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1_train,X1_test,y_train,y_test = train_test_split(X1,y,test_size =0.333, random_state = 42)\n",
    "X2_train,X2_test,y_train,y_test = train_test_split(X2,y,test_size =0.333, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "28d5d8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of GaussianNB() is:0.7233333333333334\n",
      "Accuracy score of MultinomialNB() is:0.8033333333333333\n",
      "Accuracy score of BernoulliNB() is:0.73\n",
      "Accuracy score of SVC() is:0.7566666666666667\n",
      "Accuracy score of LogisticRegression() is:0.7733333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifiers = [GaussianNB(), MultinomialNB(), BernoulliNB(), SVC(), LogisticRegression()]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X1_train, y_train)\n",
    "    y_pred = classifier.predict(X1_test)\n",
    "    print(\"Accuracy score of {} is:{}\".format(classifier, accuracy_score(y_test, y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "dea36977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of GaussianNB() is:0.71\n",
      "Accuracy score of MultinomialNB() is:0.8033333333333333\n",
      "Accuracy score of BernoulliNB() is:0.7466666666666667\n",
      "Accuracy score of SVC() is:0.7433333333333333\n",
      "Accuracy score of LogisticRegression() is:0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    classifier.fit(X2_train, y_train)\n",
    "    y_pred = classifier.predict(X2_test)\n",
    "    print(\"Accuracy score of {} is:{}\".format(classifier, accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7dc98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
